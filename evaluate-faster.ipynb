{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from os2d.modeling.model import build_os2d_from_config\n",
    "\n",
    "from os2d.data.dataloader import build_eval_dataloaders_from_cfg, build_train_dataloader_from_config\n",
    "from os2d.engine.train import trainval_loop\n",
    "from os2d.engine.evaluate import evaluate\n",
    "from os2d.utils import set_random_seed, get_trainable_parameters, mkdir, save_config, setup_logger, get_data_path, read_image, get_image_size_after_resize_preserving_aspect_ratio\n",
    "from os2d.engine.optimization import create_optimizer\n",
    "from os2d.config import cfg\n",
    "from os2d.structures.feature_map import FeatureMapSize\n",
    "from os2d.structures.bounding_box import BoxList\n",
    "import matplotlib.pyplot as plt\n",
    "import  os2d.utils.visualization as visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9718b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.init.model = \"models/os2d_v2-train.pth\"\n",
    "cfg.is_cuda = torch.cuda.is_available()\n",
    "# set this to use faster convolutions\n",
    "if cfg.is_cuda:\n",
    "    assert torch.cuda.is_available(), \"Do not have available GPU, but cfg.is_cuda == 1\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# random seed\n",
    "set_random_seed(cfg.random_seed, cfg.is_cuda)\n",
    "\n",
    "# Model\n",
    "cfg.init.model = \"models/os2d_v2-train.pth\"\n",
    "#cfg.model.backbone_arch = 'simclr'\n",
    "\n",
    "net, box_coder, criterion, img_normalization, optimizer_state = build_os2d_from_config(cfg)\n",
    "\n",
    "\n",
    "def generate_predictions(input_image, class_images):\n",
    "    h, w = get_image_size_after_resize_preserving_aspect_ratio(h=input_image.size[1],\n",
    "                                                               w=input_image.size[0],\n",
    "                                                               target_size=1500)\n",
    "    input_image = input_image.resize((w, h))\n",
    "    square_size = min(w, h)\n",
    "    transform_image = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      #transforms.Resize((2*w, 2*h)),\n",
    "                      #transforms.CenterCrop(square_size),\n",
    "                      transforms.Normalize(img_normalization[\"mean\"], img_normalization[\"std\"])\n",
    "                      ])\n",
    "    input_image_th = transform_image(input_image)\n",
    "\n",
    "    input_image_th = input_image_th.unsqueeze(0)\n",
    "    if cfg.is_cuda:\n",
    "        input_image_th = input_image_th.cuda()\n",
    "\n",
    "    ## Resize class image\n",
    "    class_images_th = []\n",
    "    for class_image in class_images:\n",
    "        h, w = get_image_size_after_resize_preserving_aspect_ratio(h=class_image.size[1],\n",
    "                                                                w=class_image.size[0],\n",
    "                                                                target_size=cfg.model.class_image_size)\n",
    "        class_image = class_image.resize((w, h))\n",
    "        square_size = min(w, h)\n",
    "        transform_image = transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      #transforms.Resize((3*w, 3*h)),\n",
    "                      #transforms.CenterCrop(square_size),\n",
    "                      transforms.Normalize(img_normalization[\"mean\"], img_normalization[\"std\"])\n",
    "                      ])\n",
    "        class_image_th = transform_image(class_image)\n",
    "        if cfg.is_cuda:\n",
    "            class_image_th = class_image_th.cuda()\n",
    "\n",
    "        class_images_th.append(class_image_th)\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        loc_prediction_batch, class_prediction_batch, _, fm_size, transform_corners_batch = net(images=input_image_th, class_images=class_images_th)\n",
    "\n",
    "\n",
    "    image_loc_scores_pyramid = [loc_prediction_batch[0]]\n",
    "    image_class_scores_pyramid = [class_prediction_batch[0]]\n",
    "    img_size_pyramid = [FeatureMapSize(img=input_image_th)]\n",
    "    transform_corners_pyramid = [transform_corners_batch[0]]\n",
    "    boxes = box_coder.decode_pyramid(image_loc_scores_pyramid, image_class_scores_pyramid,\n",
    "                                           img_size_pyramid, class_ids,\n",
    "                                           nms_iou_threshold=cfg.eval.nms_iou_threshold,\n",
    "                                           nms_score_threshold=cfg.eval.nms_score_threshold,\n",
    "                                           transform_corners_pyramid=transform_corners_pyramid)\n",
    "    print(boxes.bbox_xyxy.shape, image_loc_scores_pyramid.shape)\n",
    "    asdf\n",
    "    return boxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annspath = '../data/LogoDet-3K_os2d/val-logodet3k/classes/val-annotations.csv'\n",
    "imgspath = '../data/LogoDet-3K_os2d/val-logodet3k/src/images'\n",
    "querypath = '../data/LogoDet-3K_os2d/val-logodet3k/classes/images'\n",
    "save_path = 'detections/logodet3k_detections.pth'\n",
    "\n",
    "anns = pd.read_csv(annspath)\n",
    "\n",
    "imageids = np.unique(anns['imageid'])\n",
    "\n",
    "boxes = []\n",
    "gt_boxes = []\n",
    "image_ids = []\n",
    "\n",
    "t0 = time.time()\n",
    "for imageid in imageids:\n",
    "    image_ids.append(imageid)\n",
    "    imgdf = anns[anns['imageid'] == imageid]\n",
    "    img = Image.open(f'{imgspath}/{imageid}.jpg').convert(\"RGB\")\n",
    "    size = FeatureMapSize(img=img)\n",
    "    gt_box_t = torch.tensor(np.array(anns[['lx','ty','rx','by']]))\n",
    "    gt_box = BoxList(gt_box_t, size)\n",
    "    gt_box.add_field('labels', torch.tensor(np.array(imgdf['classid'])))\n",
    "    \n",
    "    classids = np.unique(imgdf['classid'])\n",
    "    class_imgs = [Image.open(f'{querypath}/{classid}.jpg').convert(\"RGB\") for classid in classids]\n",
    "    \n",
    "    boxes.append(generate_predictions(img, class_imgs))\n",
    "    gt_boxes.append(gt_box)\n",
    "    tnow = time.time()\n",
    "    print(imageid, tnow - t0)\n",
    "    t0 = tnow\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_xyxy = []\n",
    "for box in boxes:\n",
    "    box_xyxy = box.bbox_xyxy.clone()\n",
    "    box_xyxy[:,0] = box_xyxy[:,0] / box.image_size.w\n",
    "    box_xyxy[:,1] = box_xyxy[:,1] / box.image_size.h\n",
    "    box_xyxy[:,2] = box_xyxy[:,2] / box.image_size.w\n",
    "    box_xyxy[:,3] = box_xyxy[:,3] / box.image_size.h\n",
    "    boxes_xyxy.append(box_xyxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4558c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [box.get_field('labels') for box in boxes]\n",
    "gt_labels = [box.get_field('labels') for box in gt_boxes]\n",
    "scores = [box.get_field('scores') for box in boxes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db56b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"image_ids\" : image_ids,\n",
    "        \"boxes_xyxy\" : boxes_xyxy, \n",
    "        \"labels\" : labels,\n",
    "        \"scores\" : scores,\n",
    "        \"gt_boxes_xyxy\" : [bb.bbox_xyxy for bb in gt_boxes],\n",
    "        \"gt_labels\" : gt_labels\n",
    "        }\n",
    "torch.save(data, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e43f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f80f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
